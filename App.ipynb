{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6037bb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:42] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-component-suites/dash/dcc/async-markdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"GET /_dash-component-suites/dash/dcc/async-highlight.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:43] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"GET /_dash-component-suites/dash/dash_table/async-highlight.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"GET /_dash-component-suites/dash/dash_table/async-table.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:48] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:49] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:29:53] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:02] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "las/28.58_47.93.LAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Nov/2021 14:30:35] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:35] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:35] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:53] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:53] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:53] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:30:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:19] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:20] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Nov/2021 14:31:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "las/25.16_49.29.LAS\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import dash\n",
    "import dash_table as dt\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import Dash, html, Input, Output, callback_context\n",
    "import dash_table as dt\n",
    "from dash_table import DataTable\n",
    "import plotly.express as px\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  boto3\n",
    "\n",
    "\n",
    "bucket_for_visualization=\"transformed-for-visualization-data-1\"\n",
    "bucket_for_metadata=\"for-metadata\"\n",
    "bucket_for_download=\"transformed-for-download-data\"\n",
    "folders_name_for_visualization = ['csv/']#['curves', 'stratigraphy']\n",
    "folders_name_for_download = ['las/']\n",
    "list_metadata_files = ['List_of_curves.csv', 'List_of_data.csv']\n",
    "# for display information\n",
    "list_metadata = ['Age', 'Name', 'Type', 'lat', 'lon', 'Depth_start', 'Depth_finish', \n",
    "                 'Special_mark','Reference']\n",
    "\n",
    "geotime_list = [ 'Eocene', 'Late_Jurassic', 'Jurassic', \n",
    "                'Late Permian_Early Triassic', 'Late Carboniferous_Early Permian',]\n",
    "# log curves with different axis scale\n",
    "list_mnemonics_log500 = ['GR']\n",
    "list_mnemonics_log2000 =  ['PERM']\n",
    "list_mnemonics_RES = ['RESD', 'RESS',]\n",
    "list_mnemonics = ['SO', 'DT', 'RHOB']\n",
    "\n",
    "def make_client_resource():\n",
    "    \"\"\"\n",
    "    Connect with s3 aws.\n",
    "    \"\"\"\n",
    "    client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIA23DKJEGCA4DT3R4G',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'us-east-2'\n",
    "                           )\n",
    "    # Creating the high level object oriented interface\n",
    "    resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIA23DKJEGCA4DT3R4G',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'us-east-2'\n",
    "                             )\n",
    "    return client, resource\n",
    "\n",
    "\n",
    "def find_number_file_name(list_dir, key_word):\n",
    "    for i in range(len(list_dir)):\n",
    "        s1 = list_dir[i]\n",
    "        dirs = s1.split('/')\n",
    "        if len(dirs) > 2:\n",
    "            mnemonics = dirs[2].split('.')[0]\n",
    "            if mnemonics == key_word:\n",
    "                return i\n",
    "\n",
    "\n",
    "def find_number_lasfile_name(list_dir, key_word):\n",
    "    for i in range(1, len(list_dir)):\n",
    "        s1 = list_dir[i]\n",
    "        filename = s1.split('/')[-1]\n",
    "        mnemonics = filename.split('.LAS')[0]\n",
    "        if mnemonics == key_word:\n",
    "            return i\n",
    "\n",
    "        \n",
    "def read_curves_csv(client, datadir, option, type_curve):\n",
    "    \n",
    "    keys_log = [obj['Key'] for obj in client.list_objects_v2(\n",
    "                Bucket=datadir, Prefix=option)['Contents']]\n",
    "    \n",
    "    number_file = find_number_file_name(keys_log, type_curve)\n",
    "    path_file = keys_log[number_file]\n",
    "    obj = client.get_object(Bucket = datadir,\n",
    "                                Key = path_file\n",
    "                                )\n",
    "    return pd.read_csv(obj['Body'])\n",
    "\n",
    "\n",
    "def read_resource_metadata_csv(client, datadir, metadata_file_name, \n",
    "                               *args, make_change = False, num_col = None):\n",
    "    \n",
    "    keys_loc = [obj['Key'] for obj in client.list_objects_v2(\\\n",
    "                Bucket=datadir, Prefix=metadata_file_name)['Contents']]\n",
    "    \n",
    "    obj = client.get_object(Bucket=datadir, Key=keys_loc[0])\n",
    "    file_content = pd.read_csv(obj['Body'])\n",
    "    \n",
    "    if make_change:\n",
    "        column = file_content.columns[num_col]\n",
    "        file_content[column] = pd.Categorical(file_content[column].tolist(), \n",
    "                                              categories = list(args)[0])\n",
    "        file_content = file_content.sort_values(by=column).reset_index(drop=True)\n",
    "        \n",
    "    return file_content\n",
    "\n",
    "\n",
    "client, recourse = make_client_resource()\n",
    "\n",
    "curves_data = read_resource_metadata_csv(client, bucket_for_metadata, list_metadata_files[0])\n",
    "table_data = read_resource_metadata_csv(client, bucket_for_metadata, list_metadata_files[1], \n",
    "                                            geotime_list, make_change=True, num_col=0)\n",
    "\n",
    "#### Vizualization map and wells#################################################\n",
    "\n",
    "wells_map = curves_data[['lat', 'lon', 'Name']] \n",
    "wells_map = wells_map.set_index(['lat']).drop_duplicates()\n",
    "wells_map = wells_map.rename_axis('lat').reset_index()\n",
    "    \n",
    "px.set_mapbox_access_token(\n",
    "                          \"pk.eyJ1IjoieXVyaXlrYXByaWVsb3YiLCJhIjoiY2t2YjBiNXl2NDV4YzJucXcwcXdtZHVveiJ9.JSi7Xwold-yTZieIc264Ww\"\n",
    "                           )\n",
    "fig_map = px.scatter_mapbox(wells_map, lat=\"lat\", lon=\"lon\",  zoom=4, mapbox_style='satellite', height= 700\n",
    "                            )\n",
    "fig_map.layout.template = 'plotly_dark'\n",
    "fig_map.update_layout(clickmode='event+select')\n",
    "fig_map.update_traces(marker_size=7)\n",
    "\n",
    "fig_logs = tools.make_subplots(rows=1, cols=1).\\\n",
    "                                  update_xaxes(side='top', ticklabelposition=\"inside\",\n",
    "                                               title_standoff = 25)\n",
    "\n",
    "#### Dash Layer #######################################################################################\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG])#[dbc.themes.BOOTSTRAP, dbc.themes.DARKLY])\n",
    "\n",
    "app.layout = html.Div([ \n",
    "                        dbc.Row([\n",
    "                                 dbc.Col(html.Div(id='space'), md=2),\n",
    "                                 dbc.Col(dcc.Graph(id='basic-interactions', figure=fig_map), md=8),\n",
    "                                 dbc.Col(html.Div(id='space_1'), md=2)\n",
    "                                ],\n",
    "                                ),\n",
    "                       \n",
    "    \n",
    "\n",
    "    html.Div(className='row', children=[\n",
    "        html.Div([\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **Selected Wells**\n",
    "                            \"\"\"),\n",
    "            \n",
    "            dbc.Row([dbc.Col(html.Div(id='my-output'), md=5),\n",
    "                     dbc.Col(html.Div(id='logs'), lg=7)\n",
    "                    ]),\n",
    "            html.Div([html.Button(\"Download Las File\", id=\"btn-download-las\", n_clicks=0),\n",
    "                      html.Div(id='downloaded')\n",
    "                      #dcc.Download(id=\"download-las\")\n",
    "                    ]),\n",
    "            \n",
    "                   ], \n",
    "            ),\n",
    "  \n",
    "    ])\n",
    "])\n",
    "\n",
    "\n",
    "## Callbacks ##############################################################################################\n",
    "\n",
    "@app.callback(Output('my-output', 'children'),\n",
    "              Input('basic-interactions', 'selectedData'))\n",
    "def display_click_data(clickData):\n",
    "    if clickData:\n",
    "        with open('data.json', 'w') as f:\n",
    "            data = json.dumps(clickData, indent=2)\n",
    "            json.dump(data, f)\n",
    "        \n",
    "        data = str(json.loads(json.dumps(clickData, indent=2)))\n",
    "        \n",
    "        ys = re.findall(r\"'lat': \\d\\d.\\d\\d\", data)\n",
    "        ys_3 = re.findall(r\"'lat': \\d\\d.\\d\", data)\n",
    "        for y_3 in ys_3:\n",
    "            if y_3 not in re.findall(r\"'lat': \\d\\d.\\d\", \" \".join(ys)):\n",
    "                ys.append(y_3)\n",
    "        xs = re.findall(r\"'lon': \\d\\d.\\d\\d\", data)\n",
    "        xs_3 = re.findall(r\"'lon': \\d\\d.\\d\", data)\n",
    "        for x_3 in xs_3:\n",
    "            if x_3 not in re.findall(r\"'lon': \\d\\d.\\d\", \" \".join(xs)):\n",
    "                xs.append(x_3)\n",
    "    \n",
    "        x = []\n",
    "        y = []\n",
    "        for x_s, y_s in zip(xs, ys):\n",
    "            if re.findall(r'\\d\\d.\\d\\d',x_s) !=[]:\n",
    "                x_number = float(re.findall(r'\\d\\d.\\d\\d',x_s)[0])\n",
    "            else:\n",
    "                x_number = float(re.findall(r'\\d\\d.\\d',x_s)[0])\n",
    "            x.append(x_number)\n",
    "            if re.findall(r'\\d\\d.\\d\\d',y_s) !=[]:\n",
    "                y_number = float(re.findall(r'\\d\\d.\\d\\d',y_s)[0])\n",
    "            else:\n",
    "                y_number = float(re.findall(r'\\d\\d.\\d',y_s)[0])\n",
    "            y.append(y_number)\n",
    "            \n",
    "        \n",
    "        well_curves = curves_data[['Age', 'lat', 'lon', 'Type', 'Name']]\n",
    "        df_ = well_curves[(well_curves['lon'].isin(x)) & (well_curves['lat'].isin(y))]\n",
    "        table = DataTable(id='my-output_1',\n",
    "                          columns = [{'name': col, 'id': col} for col in df_.columns],\n",
    "                          data = df_.to_dict('records'),\n",
    "                          filter_action='native',\n",
    "                          style_cell={'textAlign': 'left'},\n",
    "                          style_data={\n",
    "                                      'color': 'white',\n",
    "                                      'backgroundColor': 'black',\n",
    "                                      'width': '75px', 'minWidth': '75px', 'maxWidth': '75px',\n",
    "                                      'overflow': 'hidden',\n",
    "                                      'textOverflow': 'ellipsis'\n",
    "                                     },\n",
    "                          style_header={\n",
    "                                        'backgroundColor': 'rgb(210, 210, 210)',\n",
    "                                        'color': 'black',\n",
    "                                        'fontWeight': 'bold'\n",
    "                                        },\n",
    "                          \n",
    "                          sort_action=\"native\",\n",
    "                          sort_mode=\"multi\",\n",
    "                          column_selectable=\"single\",\n",
    "                          row_selectable=\"multi\",\n",
    "                          row_deletable=True,\n",
    "                          selected_rows=[],\n",
    "                          page_action=\"native\",\n",
    "                          page_current= 0,\n",
    "                          page_size= 10,\n",
    "                         )\n",
    "\n",
    "        return table\n",
    "                       \n",
    "\n",
    "@app.callback(\n",
    "              Output('logs', 'children'),\n",
    "              Input('my-output_1', \"derived_virtual_data\"),\n",
    "              Input('my-output_1', \"derived_virtual_selected_rows\")\n",
    "              )\n",
    "def display_logs(rows, derived_virtual_selected_rows):\n",
    "       \n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "    \n",
    "    if derived_virtual_selected_rows!=[]:\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        selected_rows = df[df.index.isin(derived_virtual_selected_rows)]\n",
    "        cols_ = selected_rows.shape[0]\n",
    "        fig = tools.make_subplots(rows=1, cols=cols_).\\\n",
    "                                  update_xaxes(side='top', ticklabelposition=\"inside\",\n",
    "                                               title_standoff = 25)\n",
    "        for i in range(0, cols_):\n",
    "                type_curve = selected_rows.iloc[i:i+1]['Type'].values[0]\n",
    "                data_curves = read_curves_csv(client, bucket_for_visualization, \n",
    "                                              folders_name_for_visualization[0], type_curve)\n",
    "                columns_curves = data_curves.columns\n",
    "                wellname = selected_rows.iloc[i:i+1]['Name'].values[0]\n",
    "                lat =  selected_rows.iloc[i:i+1]['lat'].values[0]\n",
    "                lon =  selected_rows.iloc[i:i+1]['lon'].values[0]                \n",
    "                                        \n",
    "                y = data_curves[(data_curves['Well_name']==wellname) & \n",
    "                                (data_curves['lat']==lat) & \n",
    "                               (data_curves['lon']==lon)][columns_curves[0]]\n",
    "                x = data_curves[(data_curves['Well_name']==wellname) & \n",
    "                                (data_curves['lat']==lat) & \n",
    "                               (data_curves['lon']==lon)][columns_curves[1]]\n",
    "            \n",
    "                fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name=wellname + '_'+ type_curve), 1, i+1)\n",
    "            \n",
    "                if selected_rows.iloc[i:i+1]['Type'].values[0] in list_mnemonics_log500:\n",
    "                    fig.update_yaxes(autorange=\"reversed\")\n",
    "                    fig.update_xaxes(type=\"log\",range=[np.log10(1), np.log10(500)],  row=1, col=i+1)\n",
    "                elif(selected_rows.iloc[i:i+1]['Type'].values[0]=='NPHI') or\\\n",
    "                    (selected_rows.iloc[i:i+1]['Type'].values[0]=='PHI'):\n",
    "                    fig.update_yaxes(autorange=\"reversed\")\n",
    "                    fig.update_xaxes(autorange=\"reversed\", row=1, col=i+1)\n",
    "                elif(selected_rows.iloc[i:i+1]['Type'].values[0] in list_mnemonics_log2000) or\\\n",
    "                     selected_rows.iloc[i:i+1]['Type'].values[0] in list_mnemonics_RES:\n",
    "                    fig.update_yaxes(autorange=\"reversed\")\n",
    "                    fig.update_xaxes(type=\"log\",range=[np.log10(1), np.log10(2000)],  row=1, col=i+1)\n",
    "                elif(selected_rows.iloc[i:i+1]['Type'].values[0] in list_mnemonics):\n",
    "                    fig.update_yaxes(autorange=\"reversed\")\n",
    "                                                 \n",
    "    \n",
    "        fig.update_layout(autosize=False, width=1000, height=1000, yaxis_range=[y.min(),y.max()])\n",
    "        fig.layout.template = 'plotly_dark'\n",
    "    \n",
    "        return  dcc.Graph(id='logs_', figure = fig)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"downloaded\", \"children\"),\n",
    "    Input(\"btn-download-las\", \"n_clicks\"),\n",
    "    Input('my-output_1', \"derived_virtual_data\"),\n",
    "    Input('my-output_1', \"derived_virtual_selected_rows\"),\n",
    "    prevent_initial_call=True,\n",
    "             )\n",
    "def load_las(n_clicks, rows, derived_virtual_selected_rows):\n",
    "    \n",
    "    changed_id = [p['prop_id'] for p in callback_context.triggered][0]\n",
    "    \n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "        \n",
    "    if 'my-output_1' not  in changed_id:\n",
    "        if n_clicks != 0:\n",
    "            if derived_virtual_selected_rows!=[]:\n",
    "                df = pd.DataFrame(rows)\n",
    "                selected_rows = df[df.index.isin(derived_virtual_selected_rows)]\n",
    "                cols_ = selected_rows.shape[0]\n",
    "        \n",
    "                for i in range(0, cols_):\n",
    "                    lat =  selected_rows.iloc[i:i+1]['lat'].values[0]\n",
    "                    lon =  selected_rows.iloc[i:i+1]['lon'].values[0]\n",
    "                \n",
    "                    Keys_las = [obj['Key'] for obj in client.list_objects_v2(Bucket=bucket_for_download, \n",
    "                                                                           Prefix=folders_name_for_download[0])\\\n",
    "                                                                           ['Contents']]\n",
    "                    numb = find_number_lasfile_name(Keys_las, ('_').join((str(lat), str(lon))))\n",
    "                 \n",
    "                    try:\n",
    "                        client.download_file(bucket_for_download, Keys_las[numb], 'xxx.las')\n",
    "                    except botocore.exceptions.ClientError as e:\n",
    "                        if e.response['Error']['Code'] == \"404\":\n",
    "                            print(\"The object does not exist.\")\n",
    "                        else:\n",
    "                            raise\n",
    "                        \n",
    "                    print(Keys_las[numb])\n",
    "        \n",
    "                \n",
    "                    return 'Downloaded'#dcx.send_file(path) #dict(content=\"las\", filename=filename)\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0bb77",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce7fc8",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:gds_dash_jupynote_env] *",
   "language": "python",
   "name": "conda-env-gds_dash_jupynote_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
